{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lens Kit Class Scratch \n",
    "\n",
    "## Goals:\n",
    "    Create a Lens Kit Class Object that outputs recommendations needed for RMSE and custom metrics\n",
    "     \n",
    "     \n",
    "     \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T18:27:51.199293Z",
     "start_time": "2022-05-14T18:27:51.182339Z"
    }
   },
   "outputs": [],
   "source": [
    "import lenskit.datasets  \n",
    "import time\n",
    "from lenskit import batch, topn, util\n",
    "from lenskit import crossfold as xf\n",
    "import lenskit.algorithms \n",
    "#uncomment below cell\n",
    "from lenskit.algorithms import Recommender, Predictor, als, item_knn as knn\n",
    "from lenskit import topn\n",
    "from  sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T18:27:17.160939Z",
     "start_time": "2022-05-14T18:27:17.145971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonah\\School\\1004\\finalproj\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "%cd C:/Users/jonah/School/1004/finalproj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T18:27:17.206815Z",
     "start_time": "2022-05-14T18:27:17.163930Z"
    }
   },
   "outputs": [],
   "source": [
    "#assumes dataset is in the right plaec\n",
    "ratings = lenskit.datasets.MovieLens('ml-latest-small').ratings\n",
    "#ratings = lenskit.datasets.MovieLens('ml-latest').ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T19:50:27.284845Z",
     "start_time": "2022-05-14T19:50:26.874937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-71-51089efb5dc5>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['rating'] = train['rating'].sub(train['user'].map(user_means)).fillna(train['rating'])\n",
      "<ipython-input-71-51089efb5dc5>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['rating'] = train['rating'].sub(train['item'].map(item_means)).fillna(train['rating'])\n"
     ]
    }
   ],
   "source": [
    "#change partitions to a higher number when working with large \n",
    "for i, tp in enumerate(xf.partition_users(ratings, partitions=1, method=xf.LastFrac(.4))):\n",
    "    print(i)\n",
    "    train=tp.train\n",
    "    test=tp.test\n",
    "    \n",
    "\n",
    "#create user item average values and scale them by .5\n",
    "user_means = train.groupby('user').mean().rating*.5\n",
    "item_means = train.groupby('item').mean().rating*.5\n",
    "\n",
    "#update ratings column by mapping user id, and subtracting per user half of their mean ratings from all user-item ratings\n",
    "train['rating'] = train['rating'].sub(train['user'].map(user_means)).fillna(train['rating'])\n",
    "\n",
    "#update ratings column by mapping movie id and subtrating per movie, half of it's average rating from each uesr-item rating\n",
    "train['rating'] = train['rating'].sub(train['item'].map(item_means)).fillna(train['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sanity check, test and val data are after train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create val and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T19:50:49.927648Z",
     "start_time": "2022-05-14T19:50:49.918676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18645, 4)\n",
      "305\n"
     ]
    }
   ],
   "source": [
    "#val = test.loc[test.user.isin(range(1,int(283228/2)))]\n",
    "\n",
    "\"\"\"\n",
    "changed the below to reflect how we create validation in Spark\n",
    "\"\"\"\n",
    "\n",
    "val = test.loc[test['user']%2==0]\n",
    "print(val.shape)\n",
    "print(len(set(val[\"user\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T19:50:52.380154Z",
     "start_time": "2022-05-14T19:50:52.367190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21670, 4)\n",
      "305\n"
     ]
    }
   ],
   "source": [
    "#test = test.loc[test.user.isin(range(int(283228/2),611))]\n",
    "test = test.loc[test['user']%2==1]\n",
    "print(test.shape)\n",
    "print(len(set(test[\"user\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks test and val data have no user intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T18:27:17.761332Z",
     "start_time": "2022-05-14T18:27:17.746374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(val.user.unique()).intersection(set(test.user.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T18:27:24.835746Z",
     "start_time": "2022-05-14T18:27:17.762329Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "could not load LIBBLAS: Could not find module 'libblas' (or one of its dependencies). Try using the full path with constructor syntax.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "rec.adapt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Numba is using threading layer omp - consider TBB\n",
      "found 1 potential runtime problems - see https://boi.st/lkpy-perf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users\n"
     ]
    }
   ],
   "source": [
    "model = als.BiasedMF(5, iterations=20, method='lu', progress=None, rng_spec = 5)\n",
    "print('model')\n",
    "rec= Recommender.adapt(model)\n",
    "print('rec.adapt')\n",
    "rec.fit(train)\n",
    "\n",
    "users=train.user.unique()\n",
    "print(\"users\")\n",
    "b=lenskit.batch.recommend(rec, [1,2,3,4,5], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T21:05:36.001703Z",
     "start_time": "2022-05-14T21:05:35.978764Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing_extensions import ParamSpecArgs\n",
    "from  sklearn.metrics import r2_score,mean_squared_error\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def param_search(combos_list, method, users, train, val, user_means, item_means, verbose = True):\n",
    "    \"\"\"\n",
    "    combos_list: array of tuples that we have pyspark times and accuracies for\n",
    "    method: str -either 'lu' or 'cd'\n",
    "    users: list of unique userids\n",
    "    train: train dataset\n",
    "    val: validation or test set\n",
    "    user_means: 1:1 mapping of .5 *   average movie rating for a user\n",
    "    item_means: 1:1 mapping of .5 * the average movie rating across all users\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    j= 0 \n",
    "    out_array=list()\n",
    "    for i in combos_list:\n",
    "      j+=1\n",
    "      if j % 10 == 0:\n",
    "        frac_completed = round(100*j/len(combos_list),3)\n",
    "        print(f'finished {frac_completed}% of grid search')\n",
    "        pass\n",
    "\n",
    "      model = als.BiasedMF(features = i[0], iterations = i[1], method=method, progress=None, rng_spec = 5, reg = i[2])\n",
    "      rec= Recommender.adapt(model)\n",
    "      \n",
    "      #train start time\n",
    "      train_start = time.time()\n",
    "      rec.fit(train)\n",
    "      \n",
    "      if verbose:\n",
    "          print(f'trained{i}')\n",
    "      \n",
    "      #train end time\n",
    "      train_end = time.time()\n",
    "      \n",
    "      #pred start time\n",
    "      pred_start = time.time()\n",
    "      recommendations = lenskit.batch.recommend(rec, users, 100)\n",
    "      \n",
    "      if verbose:\n",
    "          print(f'recommended{i}')\n",
    "      \n",
    "      #pred end time\n",
    "      pred_end=time.time()\n",
    "      \n",
    "      #generate metrics\n",
    "      metrics = accuracy_metrics(recommendations, val, users, train, rec, user_means, item_means)\n",
    "      \n",
    "      if verbose:\n",
    "          print(f'metrics{i}')\n",
    "        \n",
    "      train_time = train_end-train_start\n",
    "      pred_time = pred_end-pred_start\n",
    "\n",
    "      out_array.append(metrics+(round(train_time,3),round(pred_time,3)))\n",
    "      metrics = metrics + (round(train_time,3), round(pred_time,3))\n",
    "\n",
    "      with open('single_machine_small_results.txt', 'a') as output_file:\n",
    "                  output_file.write(json.dumps(metrics))\n",
    "                  output_file.write(\"\\n\")\n",
    "           \n",
    "    \n",
    "    return out_array\n",
    "\n",
    "def accuracy_metrics(recommendations, validation, users, train, rec, user_means,item_means):\n",
    "    \"\"\"\n",
    "    outputs custome precision and recall as we have calculated them\n",
    "    recommendations: DataFrame of recommendations by user\n",
    "    validation: unaltered validation df\n",
    "    model, a model object with the params we are plugging in via grid search\n",
    "    train, the training data, we have to fit the model to the training data to calculate R^2/RMSE\n",
    "    user_means -> 1:1 mapping of .5 *   average movie rating for a user\n",
    "    item_means: 1:1 mapping of .5 * the average movie rating across all users\n",
    "\n",
    "    returns: an array with  custom precision, custom recall, RMSE, R^2 in that order\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #perform inner join  \n",
    "    #print(validation.head())\n",
    "    recommendations = recommendations[[\"user\",\"item\"]]\n",
    "    inner_df = recommendations.merge(validation[[\"user\",\"item\", \"rating\"]], on =[\"user\",\"item\"], how=\"inner\")\n",
    "    \n",
    "    val_plus = validation[validation[\"rating\"]>2.5][[\"user\",\"item\"]]\n",
    "    inner_plus = inner_df[inner_df[\"rating\"]>2.5][[\"user\",\"item\"]]\n",
    "    \n",
    "    # print(len(val_plus))\n",
    "    # print(len(inner_plus))\n",
    "    # print(len(inner_df))\n",
    "    # print(len(validation))\n",
    "    #inner_plus=inner_plus[inner_plus[\"user\"]==1]\n",
    "    \n",
    "    inner = inner_df.groupby(\"user\").agg(list)\n",
    "    inner_plus_users = set((inner_plus[\"user\"]))\n",
    "    val_users=set(validation[\"user\"])\n",
    "    \n",
    "    val_plus = val_plus.groupby(\"user\").agg(list)\n",
    "    inner_plus = inner_plus.groupby(\"user\").agg(list)\n",
    "    \n",
    "    #get precision and recall by user\n",
    "    prec_array = list()\n",
    "    recall_array = list()\n",
    "    \n",
    "    for user in val_users:\n",
    "        \n",
    "        if user in inner_plus_users:\n",
    "            prec = len(inner_plus.loc[user][0])/len(inner.loc[user][0])\n",
    "            recall = len(inner_plus.loc[user][0])/len(val_plus.loc[user][0])\n",
    "            prec_array.append(prec)\n",
    "            recall_array.append(recall)\n",
    "            \n",
    "        else:\n",
    "            recall_array.append(0)\n",
    "        \n",
    "    ## start adding in Regression Evaluation Metrics:\n",
    "\n",
    "    #create predictions for user-item pairs in the validation dataset \n",
    "    RMSE_preds = lenskit.batch.predict(rec, validation, njobs = 3) #njobs can be changed, just randomly typed 4 in there\n",
    "    #remove cold start predictions \n",
    "\n",
    "    #denormalize the predictions\n",
    "    RMSE_preds['prediction'] = RMSE_preds['prediction'].add(RMSE_preds['user'].map(user_means)).fillna(RMSE_preds['prediction'])\n",
    "    RMSE_preds['prediction'] = RMSE_preds['prediction'].add(RMSE_preds['item'].map(item_means)).fillna(RMSE_preds['prediction'])\n",
    "    RMSE_preds['prediction'] -=2.5\n",
    "    \n",
    "    #subtract 2.5 from the validation dataset for RMSE purposes\n",
    "    RMSE_preds['rating'] -= 2.5\n",
    "    RMSE_preds = RMSE_preds.loc[~RMSE_preds['prediction'].isnull()]\n",
    "    rmse = mean_squared_error(RMSE_preds['rating'], RMSE_preds['prediction'])**.5\n",
    "    r_sq = r2_score(RMSE_preds['rating'], RMSE_preds['prediction'])\n",
    "    return (np.mean(prec_array),np.mean(recall_array), rmse, r_sq)\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f46892",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_list = [x*5 for x in range(0,51)]\n",
    "\n",
    "als_data = pd.read_json('results_als.txt', lines=True)\n",
    "als_data = pd.concat([als_data.drop(['metrics'], axis=1), als_data['metrics'].apply(pd.Series)], axis=1)\n",
    "\n",
    "#get all non NA l2 penalizers\n",
    "l2_list = als_data.regParam.loc[~als_data['regParam'].isnull()].unique()\n",
    "max_iter = [10]\n",
    "\n",
    "als_grid = list(itertools.product(*[rank_list,max_iter,l2_list]))\n",
    "\n",
    "users = train.user.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T21:05:40.946937Z",
     "start_time": "2022-05-14T21:05:36.722233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained(50, 10)\n",
      "recommended(50, 10)\n",
      "15243\n",
      "1248\n",
      "1425\n",
      "18645\n",
      "1\n",
      "2\n",
      "metrics(50, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.925255558634828, 0.0924359449098524, 0.374, 3.736)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos_list = [(50,10)]\n",
    "\n",
    "param_search(combos_list, \"lu\", users, train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2572528",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search(als_grid, \"lu\", users, train, val, user_means, item_means, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T18:27:28.699167Z",
     "start_time": "2022-05-14T18:27:15.654Z"
    }
   },
   "outputs": [],
   "source": [
    "a=train[[\"user\",\"item\"]].groupby(\"user\").agg(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T20:56:38.555229Z",
     "start_time": "2022-05-14T20:56:38.551267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18645"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T20:58:54.410820Z",
     "start_time": "2022-05-14T20:58:54.393865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8757894736842106"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
